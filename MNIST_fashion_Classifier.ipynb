{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Kaggle Fashion-MNIST Classifier Using Keras\n",
    "\n",
    "In this project a deep learning based classifier will be constructed using `Keras` and `Tensorflow`. This is part of the Deep Learning course of Kaggle. The dataset can be found [here](https://www.kaggle.com/zalando-research/fashionmnist). This dataset contains greyscale pictures of clothes from Zalando's storefront. It is comprised of a train set containing 60,000 pictures and a test set containing 10,000 pictures. Each picture is labeled to be one of 10 classes of clothes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Select GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14380945388489136212\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9104897474\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3341627468246877851\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3135687884\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15350896844351988525\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1050 Ti, pci bus id: 0000:25:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import os\n",
    "os.environ['TF_MIN_GPU_MULTIPROCESSOR_COUNT']='4'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the dataset each picture is 28x28 pixels\n",
    "img_rows, img_cols = 28, 28\n",
    "# There are 10 classes of clothing in the dataset\n",
    "num_classes = 10\n",
    "\n",
    "def prep_data(raw):\n",
    "    '''Prepare data for use by the deep learning model\n",
    "    Args:\n",
    "        raw (numpy array): array containing the raw dataset to transform\n",
    "    Returns:\n",
    "        numpy array, numpy array: transformed datasets of data and labels ready for use by the ml model\n",
    "    '''\n",
    "    # separate and one-hot encode labels\n",
    "    y = raw[:,0]\n",
    "    out_y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    # cut out values, reshape them and normalize the color intensity values\n",
    "    x = raw[:, 1:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    \n",
    "    return out_x, out_y\n",
    "\n",
    "fashion_file = \"./fashion-mnist_train.csv\"\n",
    "fashion_data = np.loadtxt(fashion_file, skiprows = 1, delimiter = ',')\n",
    "x, y = prep_data(fashion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.4016 - accuracy: 0.8547 - val_loss: 0.3123 - val_accuracy: 0.8900\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 0.2514 - accuracy: 0.9070 - val_loss: 0.2556 - val_accuracy: 0.9079\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 0.1847 - accuracy: 0.9303 - val_loss: 0.2582 - val_accuracy: 0.9089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f33560748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "batch_size = 16\n",
    "\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(16, kernel_size = (3,3),\n",
    "                        activation = 'relu',\n",
    "                        input_shape = (img_rows, img_cols, 1)))\n",
    "fashion_model.add(Conv2D(16, kernel_size = (3,3), activation = 'relu'))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation = 'relu'))\n",
    "fashion_model.add(Dense(num_classes, activation = 'softmax'))\n",
    "fashion_model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "                     optimizer = 'adam',\n",
    "                     metrics = ['accuracy'])\n",
    "fashion_model.fit(x, y,\n",
    "                 batch_size = batch_size,\n",
    "                 epochs = 3,\n",
    "                 validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shows an accuracy of about 90 percent and takes approximately 45s to train and test on a GTX 1050 ti. Now in order to make the model more efficient some dropout layers will be added and the stride length will be increased. The first step will be to add dropout layers.\n",
    "The main benefit of adding dropout layers are that they reduce overfitting in the model. This means that the model can be made more complex and hopefully achieve an even higher accuracy score without being limited by this phenomenon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.5806 - accuracy: 0.7898 - val_loss: 0.3620 - val_accuracy: 0.8698\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 7s 142us/sample - loss: 0.4181 - accuracy: 0.8481 - val_loss: 0.3204 - val_accuracy: 0.8860\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 0.3761 - accuracy: 0.8625 - val_loss: 0.2986 - val_accuracy: 0.8912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26ecba53908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(16, kernel_size = (3,3),\n",
    "                        activation = 'relu',\n",
    "                        input_shape = (img_rows, img_cols, 1)))\n",
    "fashion_model.add(Dropout(0.5))\n",
    "fashion_model.add(Conv2D(16, kernel_size = (3,3), activation = 'relu'))\n",
    "fashion_model.add(Dropout(0.5))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation = 'relu'))\n",
    "fashion_model.add(Dropout(0.5))\n",
    "fashion_model.add(Dense(num_classes, activation = 'softmax'))\n",
    "fashion_model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "                     optimizer = 'adam',\n",
    "                     metrics = ['accuracy'])\n",
    "fashion_model.fit(x, y,\n",
    "                 batch_size = batch_size,\n",
    "                 epochs = 3,\n",
    "                 validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The model with dropout layers showed no noticeable decrease in accuracy. The training time did increase slightly, however "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the stride length in the different convolutional layers will be increased.\n",
    "Increasing the stride length of the convolutional layers means that the model training time should be reduced, with minimal impact on the resulting accuracy. The model will apply each of the convolutions less often and so will be less computationally expensive to train. Applying convolutions too often can lead to the model getting redundant information, which means that some of the calculation steps are unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 7s 139us/sample - loss: 0.6873 - accuracy: 0.7472 - val_loss: 0.4462 - val_accuracy: 0.8334\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 0.5262 - accuracy: 0.8066 - val_loss: 0.3907 - val_accuracy: 0.8602\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.4784 - accuracy: 0.8220 - val_loss: 0.3660 - val_accuracy: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26ede783e08>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(16, kernel_size = (3,3),\n",
    "                        activation = 'relu',\n",
    "                        input_shape = (img_rows, img_cols, 1)))\n",
    "fashion_model.add(Dropout(0.5))\n",
    "fashion_model.add(Conv2D(16, kernel_size = (3,3), strides = 3, activation = 'relu'))\n",
    "fashion_model.add(Dropout(0.5))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation = 'relu'))\n",
    "fashion_model.add(Dropout(0.5))\n",
    "fashion_model.add(Dense(num_classes, activation = 'softmax'))\n",
    "fashion_model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "                     optimizer = 'adam',\n",
    "                     metrics = ['accuracy'])\n",
    "fashion_model.fit(x, y,\n",
    "                 batch_size = batch_size,\n",
    "                 epochs = 3,\n",
    "                 validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the model more complex to try to increase the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 8s 156us/sample - loss: 0.4588 - accuracy: 0.8338 - val_loss: 0.3254 - val_accuracy: 0.8867\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.3060 - accuracy: 0.8859 - val_loss: 0.2755 - val_accuracy: 0.9011\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.2587 - accuracy: 0.9029 - val_loss: 0.2647 - val_accuracy: 0.9065\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 7s 150us/sample - loss: 0.2240 - accuracy: 0.9137 - val_loss: 0.2656 - val_accuracy: 0.9041\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 7s 147us/sample - loss: 0.1995 - accuracy: 0.9242 - val_loss: 0.2668 - val_accuracy: 0.9084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f0eef0588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x, y,\n",
    "          batch_size=16,\n",
    "          epochs=5,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 12s 251us/sample - loss: 0.4109 - accuracy: 0.8513 - val_loss: 0.3107 - val_accuracy: 0.8860\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 12s 244us/sample - loss: 0.2806 - accuracy: 0.8964 - val_loss: 0.2761 - val_accuracy: 0.9031\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 12s 242us/sample - loss: 0.2297 - accuracy: 0.9134 - val_loss: 0.2472 - val_accuracy: 0.9093\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.1963 - accuracy: 0.9254 - val_loss: 0.2502 - val_accuracy: 0.9109\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.1673 - accuracy: 0.9362 - val_loss: 0.2685 - val_accuracy: 0.9072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f0a4b8648>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x, y,\n",
    "          batch_size=16,\n",
    "          epochs=5,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Even with a much higher complexity and more training epochs, the model does not seem to improve much. 91% Accuracy seems to be a tough cap to break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this project the MNIST-Fashion dataset containing images of clothing from Zalando was analyzed and a Keras model was constructed to classify the pictures into 10 categories of clothing. The model was optimized for speed and to combat overfitting, to allow for a more complex model. But in the end, even a much more complex model did not perform much better than the simple one. It might be interesting to see if the accuracy of the model could be improved by augmenting the training data to gain access to a larger dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
